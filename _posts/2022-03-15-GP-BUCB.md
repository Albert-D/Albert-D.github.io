---
layout: post
title: "Parallelizing Exploration-Exploitation Tradeoffs in Gaussian Process Bandit Optimization"
date: 2022-03-15
description: [This is a brief review of paper "Parallelizing Exploration-Exploitation Tradeoffs in Gaussian Process Bandit Optimization", It is also the third paper review assignment of SDSC 8014.]
categories: [Review, Assignments for SDSC8014]
keywords: Online Convex Programming, Online Optimization, review, GP-AUCB
mathjax: true
---

This paper mainly introduce two algorithms for parallelizing exploration-exploitation tradeoﬀs in Gaussian process bandit optimization, the Gaussian Process Batch Upper Conﬁdence Bound (GP-BUCB) and Gaussian Process Adaptive Upper Conﬁdence Bound (GP-AUCB). GP-BUCB is an upper conﬁdence bound-based algorithm, which models the reward function as a sample from a Gaussian process and which can select batches of experiments to run in parallel. GP-AUCB is an algorithm which adaptively exploits parallelism to choose batches of actions.

## Contribution
- GP-BUCB is a novel algorithm for selecting actions to maximize reward in large-scale exploration-exploitation problems which
can accommodates parallel or batch execution of the actions and the consequent observation of their reward.

- GP-AUCB is an algorithm which adaptively exploits parallelism to choose batches of actions, which is is eﬀective and can easily be parameterized using pre-deﬁned limits.

- They prove sublinear bounds on the cumulative regret incurred by algorithms of a general class, including GP-BUCB and GP-AUCB.

- For some common kernels, the regret of GP-BUCB can be bounded to a constant multiplicative factor of the known regret bounds of the fully sequential GP-UCB algorithm.

- They accelerate the execution of many UCB algorithms by lazily evaluating the posterior variance darmatically.

- They evaluate GP-BUCB and GP-AUCB on several synthetic benchmark problems and show that GP-BUCB and GP-AUCB are competitive
with state-of-the-art heuristics for parallel Bayesian optimization.

## Related Work
- Exploration-exploitation tradeoﬀs have been classically studied in context of multi-armed bandit problems. In this paper they pursue a Bayesian approach to bandits, where ﬁne-grained assumptions on the regularity of the reward function can be imposed through proper choice of the prior distribution over the payoff function. 

- The exploration-exploitation tradeoﬀ has also been studied in Bayesian global optimization and response surface modeling. They build on this foundation and generalize it to the parallel setting

- They experimentally compare with some approach approach focuses on active learning for estimation, which does not involve exploration–exploitation tradeoffs.

## Content of the article

### Section 3
In section 3, they define the Problem Setting and Background. Then they deﬁne the problem setting of parallel selection and term the pessimistic view and consider the problem of coping eﬀectively under inferior feedback. They model function $$f$$ via Gaussian Processes and consider in Conditional Mutual Information. In Section 3.4, they describes the GP-UCB algorithm and discusses why some simple attempts at generalizing it to the parallel setting are insufficient.

### Section 4
In this section, they first give the GP-BUCB algorithm,

![Algorithm 1](/assets/images/22-03-15-GP-BUCB/algorithm1.png)

Then give a regret bound of GP-BUCB,

![Theorem 2](/assets/images/22-03-15-GP-BUCB/theorem2.png)

And give a Better Bounds Through Initialization,

![Theorem 5](/assets/images/22-03-15-GP-BUCB/theorem5.png)

### Section 5
In this section, they introduce GP-AUCB Algorithm 

![Algorithm 1](/assets/images/22-03-15-GP-BUCB/algorithm4.png)


and states a corollary regret bound for this algorithm.

![Corollary 6 ](/assets/images/22-03-15-GP-BUCB/corollary6.png)

### Section 6
In this section, we introduce the notion of lazy variance calculations, which may be used
to greatly accelerate the computation of many UCB-based algorithms, including GP-UCB,
GP-BUCB, and GP-AUCB, without any loss of performance.

### Section 7
In this section, they compare GP-BUCB with several alternatives.